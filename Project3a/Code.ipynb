{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from rnn1 import generate_features\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataextract(folder):\n",
    "    dataset_arm = pd.read_csv(folder + \"armIMU.txt\", sep=\"  \", header=None, engine='python')\n",
    "    dataset_wrist = pd.read_csv(folder + 'wristIMU.txt', sep=\"  \", header=None, engine='python')\n",
    "    label = pd.read_csv(folder + 'detection.txt', sep=\"  \", header=None, engine='python')\n",
    "    dataset_arm.columns = [\"aa1\", \"aa2\", \"aa3\", \"ag1\", \"ag2\", \"ag3\"]\n",
    "    dataset_wrist.columns = [\"wa1\", \"wa2\", \"wa3\", \"wg1\", \"wg2\", \"wg3\"]\n",
    "    label.columns = [\"label\"]\n",
    "    dataset = pd.concat([dataset_arm, dataset_wrist], axis=1, sort=False)\n",
    "    return dataset, label\n",
    "\n",
    "def get_train_features(X):\n",
    "    xyz = []\n",
    "    for i in range(0, len(X), 40): # 70 percent overlap\n",
    "        p = X.loc[i:i+150]\n",
    "        set1 = p.loc[:,[\"aa1\", \"aa2\", \"aa3\"]]\n",
    "        set2 = p.loc[:,[\"ag1\", \"ag2\", \"ag3\"]]\n",
    "        set3 = p.loc[:,[\"wa1\", \"wa2\", \"wa3\"]]\n",
    "        set4 = p.loc[:,[\"wg1\", \"wg2\", \"wg3\"]]\n",
    "        f1 = generate_features(set1)\n",
    "        f2 = generate_features(set2)\n",
    "        f3 = generate_features(set3)\n",
    "        f4 = generate_features(set4)\n",
    "        f = np.concatenate((f3, f4), axis=0)\n",
    "        f = np.concatenate((f1, f2, f), axis=0)\n",
    "        features=f.tolist()\n",
    "        xyz.append(features)\n",
    "    return(pd.DataFrame(xyz))\n",
    "\n",
    "def get_test_features(X):\n",
    "    xyz = []\n",
    "    for i in range(0, len(X)):\n",
    "        p = X.loc[i:i+150]\n",
    "        set1 = p.loc[:,[\"aa1\", \"aa2\", \"aa3\"]]\n",
    "        set2 = p.loc[:,[\"ag1\", \"ag2\", \"ag3\"]]\n",
    "        set3 = p.loc[:,[\"wa1\", \"wa2\", \"wa3\"]]\n",
    "        set4 = p.loc[:,[\"wg1\", \"wg2\", \"wg3\"]]\n",
    "        f1 = generate_features(set1)\n",
    "        f2 = generate_features(set2)\n",
    "        f3 = generate_features(set3)\n",
    "        f4 = generate_features(set4)\n",
    "        f = np.concatenate((f3, f4), axis=0)\n",
    "        f = np.concatenate((f1, f2, f), axis=0)\n",
    "        features=f.tolist()\n",
    "        xyz.append(features)\n",
    "    return(pd.DataFrame(xyz))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder1 = '/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Training Data/Session01/'\n",
    "train_folder2 = '/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Training Data/Session05/'\n",
    "train_folder3 = '/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Training Data/Session06/'\n",
    "train_folder4 = '/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Training Data/Session07/'\n",
    "train_folder5 ='/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Training Data/Session12/'\n",
    "train_folder6 = '/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Training Data/Session13/'\n",
    "\n",
    "Xtrain1, Ytrain1 = dataextract(train_folder1)\n",
    "Xtrain2, Ytrain2 = dataextract(train_folder2)\n",
    "Xtrain3, Ytrain3 = dataextract(train_folder3)\n",
    "Xtrain4, Ytrain4 = dataextract(train_folder4)\n",
    "Xtrain5, Ytrain5 = dataextract(train_folder5)\n",
    "Xtrain6, Ytrain6 = dataextract(train_folder6)\n",
    "\n",
    "Xtrain, Ytrain = pd.concat([Xtrain1, Xtrain2, Xtrain3, Xtrain4, Xtrain5, Xtrain6], ignore_index=True), pd.concat([Ytrain1, Ytrain2, Ytrain3, Ytrain4, Ytrain5, Ytrain6], ignore_index=True)\n",
    "Xf = get_train_features(Xtrain)\n",
    "Xf = pd.DataFrame(preprocessing.normalize(np.array(Xf)))\n",
    "Yf = pd.DataFrame([1 if any(Ytrain.iloc[i:i + 150, 0]) else 0 for i in range(0, len(Ytrain), 40)])\n",
    "Yf = np.ravel(Yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_param_selection(X, y):\n",
    "    n_estimators = [200,300,400,500]\n",
    "    max_depth = [7,8,9]\n",
    "    max_features = ['sqrt','log2']\n",
    "    param_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "              }\n",
    "    grid_search = model_selection.GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "\n",
    "    grid_search.fit(X, y)\n",
    "    return grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training\n",
      "Fitting 5 folds for each of 24 candidates, totalling 120 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:  4.1min\n",
      "[Parallel(n_jobs=-1)]: Done 120 out of 120 | elapsed: 16.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 9, 'max_features': 'sqrt', 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "print(\"Training\")\n",
    "rf = RandomForestClassifier()\n",
    "best = rf_param_selection(Xf, Yf)\n",
    "print(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=9, max_features='sqrt', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=400, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators= best['n_estimators'], max_features = best['max_features'], max_depth=best['max_depth'])\n",
    "rf1.fit(Xf, Yf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_folder1 = '/Users/akankshabhattacharyya/Downloads/NCSU/SEM2 Courses/Neural Networks/Project3/Test Data 1/Session02/'\n",
    "print(\"Testing\")\n",
    "Xtest, Ytest = dataextract(test_folder1)\n",
    "Xtf = get_test_features(Xtest)\n",
    "Xtf = Xtf.fillna(0)\n",
    "Xtf = pd.DataFrame(preprocessing.normalize(np.array(Xtf)))\n",
    "predictions = rf1.predict(Xtf)\n",
    "predicitons.to_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
