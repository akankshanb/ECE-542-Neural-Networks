{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"Untitled0.ipynb\n",
    "\n",
    "Automatically generated by Colaboratory.\n",
    "\n",
    "Original file is located at\n",
    "    https://colab.research.google.com/drive/1LuY9iF_fMf8k8FgRZaU3WtI7CmhxLRzx\n",
    "\"\"\"\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "ls \"drive/My Drive/data/\"\n",
    "\n",
    "data_path = \"drive/My Drive/data/\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import collections\n",
    "import os\n",
    "os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation, Embedding, Dropout, TimeDistributed\n",
    "from keras.layers import LSTM\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import numpy as np\n",
    "import argparse\n",
    "\n",
    "f= open (data_path+'ptb.train.txt')\n",
    "data = f.read().replace(\"\\n\", \"<eos>\").split(\" \")\n",
    "counter = collections.Counter(data)\n",
    "words, _ = list(zip(*counter.items()))\n",
    "word_to_id = dict(zip(words, range(len(words))))\n",
    "id_to_word = dict([[v,k] for k,v in word_to_id.items()])\n",
    "vocab_length = len(word_to_id)\n",
    "\n",
    "f= open (data_path+'ptb.char.train.txt')\n",
    "data = f.read().replace(\"\\n\", \"<eos>\").split(\" \")\n",
    "counter = collections.Counter(data)\n",
    "characters, _ = list(zip(*counter.items()))\n",
    "char_to_id = dict(zip(words, range(len(characters))))\n",
    "id_to_word = dict([[v,k] for k,v in word_to_id.items()])\n",
    "vocab_char_length = len(word_to_id)\n",
    "\n",
    "def file_to_word_ids(filename, word_to_id):\n",
    "    f= open (filename)\n",
    "    data = f.read().replace(\"\\n\", \"<eos>\").split(\" \")\n",
    "    return [word_to_id[word] for word in data if word in word_to_id]\n",
    "\n",
    "train_data = file_to_word_ids(data_path+'ptb.train.txt', word_to_id)\n",
    "valid_data = file_to_word_ids(data_path+'ptb.valid.txt', word_to_id)\n",
    "test_data = file_to_word_ids(data_path+ 'ptb.test.txt', word_to_id)\n",
    "\n",
    "train_char_data = file_to_word_ids(data_path+'ptb.char.train.txt', word_to_id)\n",
    "valid_char_data = file_to_word_ids(data_path+'ptb.char.valid.txt', word_to_id)\n",
    "test_char_data = file_to_word_ids(data_path+ 'ptb.char.test.txt', word_to_id)\n",
    "\n",
    "class KerasBatchGenerator(object):\n",
    "\n",
    "    def __init__(self, data, num_steps, batch_size, vocabulary, skip_step=5):\n",
    "        self.data = data\n",
    "        self.num_steps = num_steps\n",
    "        self.batch_size = batch_size\n",
    "        self.vocabulary = vocabulary\n",
    "        self.current_idx = 0\n",
    "        self.skip_step = skip_step\n",
    "\n",
    "    def generate(self):\n",
    "        x = np.zeros((self.batch_size, self.num_steps))\n",
    "        y = np.zeros((self.batch_size, self.num_steps, self.vocabulary))\n",
    "        while True:\n",
    "            for i in range(self.batch_size):\n",
    "                if self.current_idx + self.num_steps >= len(self.data):\n",
    "                    self.current_idx = 0\n",
    "                x[i, :] = self.data[self.current_idx:self.current_idx + self.num_steps]\n",
    "                temp_y = self.data[self.current_idx + 1:self.current_idx + self.num_steps + 1]\n",
    "                y[i, :, :] = to_categorical(temp_y, num_classes=self.vocabulary)\n",
    "                self.current_idx += self.skip_step\n",
    "            yield x, y\n",
    "\n",
    "num_steps = 20\n",
    "batch_size = 20\n",
    "embed_size = 500\n",
    "train_data_generator = KerasBatchGenerator(train_data, num_steps, batch_size, vocab_length)\n",
    "valid_data_generator = KerasBatchGenerator(valid_data, num_steps, batch_size, vocab_length)\n",
    "\n",
    "import keras.backend as K\n",
    "\n",
    "# Custom error metric\n",
    "def perplexity(y_true, y_pred):\n",
    "    #y_true_onehot = to_categorical(y_true, num_classes=10001)\n",
    "    return K.pow(2.0, K.mean(K.categorical_crossentropy(y_true, y_pred)))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_length, embed_size, input_length=num_steps))\n",
    "model.add(LSTM(embed_size, return_sequences=True))\n",
    "model.add(LSTM(embed_size, return_sequences=True))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(TimeDistributed(Dense(vocab_length)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = Adam(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy',perplexity])\n",
    "\n",
    "#plot_model(model,to_file= data_path + 'model_plot.png', show_shapes=True, show_layer_names=True)\n",
    "print(model.summary())\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath=data_path + '/model-{epoch:02d}.hdf5', verbose=1)\n",
    "num_epochs = 20\n",
    "train_steps = len(train_data)//(batch_size*num_steps)\n",
    "valid_steps=len(valid_data)//(batch_size*num_steps)\n",
    "hist = model.fit_generator(train_data_generator.generate(), train_steps, num_epochs,\n",
    "                    validation_data=valid_data_generator.generate(),\n",
    "                    validation_steps=valid_steps, callbacks=[checkpointer])\n",
    "model.save(data_path + \"final_model.hdf5\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(hist.history['perplexity'], 'b')\n",
    "plt.plot(hist.history['val_perplexity'], 'r')\n",
    "plt.title('Perplexity Measure for Word Model')\n",
    "plt.ylabel('Perplexity')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "hist.history['perplexity']\n",
    "\n",
    "# model = load_model(data_path + \"\\model-40.hdf5\")\n",
    "# dummy_iters = 40\n",
    "# example_training_generator = KerasBatchGenerator(train_data, num_steps, 1, vocabulary,\n",
    "#                                                  skip_step=1)\n",
    "# print(\"Training data:\")\n",
    "# for i in range(dummy_iters):\n",
    "#     dummy = next(example_training_generator.generate())\n",
    "# num_predict = 10\n",
    "# true_print_out = \"Actual words: \"\n",
    "# pred_print_out = \"Predicted words: \"\n",
    "# for i in range(num_predict):\n",
    "#     data = next(example_training_generator.generate())\n",
    "#     prediction = model.predict(data[0])\n",
    "#     predict_word = np.argmax(prediction[:, num_steps-1, :])\n",
    "#     true_print_out += reversed_dictionary[train_data[num_steps + dummy_iters + i]] + \" \"\n",
    "#     pred_print_out += reversed_dictionary[predict_word] + \" \"\n",
    "# print(true_print_out)\n",
    "# print(pred_print_out)\n",
    "# test data set\n",
    "dummy_iters = 40\n",
    "test_generator = KerasBatchGenerator(test_data, num_steps, 1, vocab_length,skip_step=1)\n",
    "print(\"Test data:\")\n",
    "for i in range(dummy_iters):\n",
    "    dummy = next(test_generator.generate())\n",
    "num_predict = 100\n",
    "true_print_out = \"Actual words: \"\n",
    "pred_print_out = \"Predicted words: \"\n",
    "for i in range(num_predict):\n",
    "    data = next(example_test_generator.generate())\n",
    "    prediction = model.predict(data[0])\n",
    "    predict_word = np.argmax(prediction[:, num_steps - 1, :])\n",
    "    true_print_out += id_to_word[test_data[num_steps + dummy_iters + i]] + \" \"\n",
    "    pred_print_out += id_to_word[predict_word] + \" \"\n",
    "print(true_print_out)\n",
    "print(pred_print_out)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
